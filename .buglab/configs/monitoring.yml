# Monitoring configuration for Fixer & Orchestrator v3.0
# Defines metrics, alerts, and observability settings

monitoring:
  # Application metrics
  metrics:
    # Code quality metrics
    code_quality:
      mypy_errors:
        type: gauge
        description: "Number of MyPy type checking errors"
        thresholds:
          warning: 100
          critical: 500
      
      test_coverage:
        type: gauge
        description: "Test coverage percentage"
        thresholds:
          warning: 70
          critical: 50
      
      security_vulnerabilities:
        type: gauge
        description: "Number of security vulnerabilities found"
        thresholds:
          warning: 5
          critical: 10
    
    # Performance metrics
    performance:
      test_execution_time:
        type: histogram
        description: "Test execution time in seconds"
        buckets: [1, 5, 10, 30, 60, 120]
      
      memory_usage:
        type: gauge
        description: "Memory usage in MB"
        thresholds:
          warning: 512
          critical: 1024
      
      cpu_usage:
        type: gauge
        description: "CPU usage percentage"
        thresholds:
          warning: 80
          critical: 95
    
    # Build metrics
    build:
      build_duration:
        type: histogram
        description: "Build duration in seconds"
        buckets: [30, 60, 120, 300, 600]
      
      build_success_rate:
        type: gauge
        description: "Build success rate percentage"
        thresholds:
          warning: 90
          critical: 80

  # Alerting configuration
  alerts:
    # Code quality alerts
    code_quality_alerts:
      - name: "High MyPy Error Count"
        condition: "mypy_errors > 500"
        severity: "critical"
        message: "MyPy error count is critically high: {{ $value }}"
        cooldown: "1h"
      
      - name: "Low Test Coverage"
        condition: "test_coverage < 50"
        severity: "critical"
        message: "Test coverage is critically low: {{ $value }}%"
        cooldown: "1h"
      
      - name: "Security Vulnerabilities Detected"
        condition: "security_vulnerabilities > 10"
        severity: "critical"
        message: "Critical security vulnerabilities detected: {{ $value }}"
        cooldown: "30m"
    
    # Performance alerts
    performance_alerts:
      - name: "High Memory Usage"
        condition: "memory_usage > 1024"
        severity: "warning"
        message: "High memory usage detected: {{ $value }}MB"
        cooldown: "15m"
      
      - name: "High CPU Usage"
        condition: "cpu_usage > 95"
        severity: "warning"
        message: "High CPU usage detected: {{ $value }}%"
        cooldown: "15m"
      
      - name: "Slow Test Execution"
        condition: "test_execution_time > 300"
        severity: "warning"
        message: "Test execution is taking too long: {{ $value }}s"
        cooldown: "30m"
    
    # Build alerts
    build_alerts:
      - name: "Build Failure"
        condition: "build_success_rate < 80"
        severity: "critical"
        message: "Build success rate is critically low: {{ $value }}%"
        cooldown: "1h"
      
      - name: "Slow Build"
        condition: "build_duration > 600"
        severity: "warning"
        message: "Build is taking too long: {{ $value }}s"
        cooldown: "30m"

  # Logging configuration
  logging:
    level: "INFO"
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    handlers:
      - type: "file"
        filename: ".buglab/logs/application.log"
        max_bytes: 10485760  # 10MB
        backup_count: 5
      
      - type: "file"
        filename: ".buglab/logs/error.log"
        level: "ERROR"
        max_bytes: 10485760  # 10MB
        backup_count: 5
      
      - type: "console"
        level: "WARNING"

  # Health checks
  health_checks:
    - name: "Code Quality Check"
      command: "mypy . --config-file mypy.ini"
      timeout: "60s"
      interval: "1h"
      failure_threshold: 3
    
    - name: "Test Suite Check"
      command: "pytest --cov=. --cov-fail-under=80"
      timeout: "300s"
      interval: "2h"
      failure_threshold: 2
    
    - name: "Security Scan Check"
      command: "semgrep --config=.buglab/configs/semgrep.yml"
      timeout: "120s"
      interval: "6h"
      failure_threshold: 3
    
    - name: "Documentation Check"
      command: "test -f DocsPro/_index.md"
      timeout: "10s"
      interval: "1h"
      failure_threshold: 5

  # Dashboard configuration
  dashboard:
    title: "Fixer & Orchestrator v3.0 - Quality Dashboard"
    refresh_interval: "5m"
    panels:
      - title: "Code Quality Overview"
        type: "stat"
        metrics: ["mypy_errors", "test_coverage", "security_vulnerabilities"]
      
      - title: "Performance Overview"
        type: "graph"
        metrics: ["test_execution_time", "memory_usage", "cpu_usage"]
      
      - title: "Build Status"
        type: "stat"
        metrics: ["build_duration", "build_success_rate"]
      
      - title: "Recent Alerts"
        type: "table"
        query: "alerts"
        limit: 10

  # Exporters
  exporters:
    prometheus:
      enabled: true
      port: 9090
      path: "/metrics"
    
    grafana:
      enabled: true
      url: "http://localhost:3000"
      api_key: "${GRAFANA_API_KEY}"
    
    slack:
      enabled: true
      webhook_url: "${SLACK_WEBHOOK_URL}"
      channel: "#quality-alerts"